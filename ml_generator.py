"""
Machine Learning Code Generator
Generates complete ML pipelines with scikit-learn
"""

import re
from datetime import datetime


class MLGenerator:
    """Generate machine learning code for various tasks"""
    
    def __init__(self):
        self.supported_models = {
            'classification': ['RandomForest', 'SVM', 'LogisticRegression', 'XGBoost'],
            'regression': ['LinearRegression', 'RandomForestRegressor', 'GradientBoosting'],
            'clustering': ['KMeans', 'DBSCAN', 'HierarchicalClustering']
        }
    
    def generate(self, project_name, description, options):
        """
        Generate complete ML project
        
        Args:
            project_name: Name of the project
            description: Project description
            options: Configuration options
        
        Returns:
            Dictionary containing generated code files
        """
        model_type = options.get('model_type', 'classification')
        include_comments = options.get('include_comments', True)
        include_tests = options.get('include_tests', False)
        include_visualization = options.get('include_visualization', True)
        
        # Generate main code
        main_code = self._generate_main_code(
            project_name, description, model_type, 
            include_comments, include_visualization
        )
        
        # Generate utilities
        utils_code = self._generate_utils_code(model_type, include_comments)
        
        # Generate requirements
        requirements = self._generate_requirements(model_type, include_visualization)
        
        # Generate README
        readme = self._generate_readme(project_name, description, model_type)
        
        # Generate tests if requested
        test_code = ''
        if include_tests:
            test_code = self._generate_tests(project_name, model_type)
        
        return {
            'main_code': main_code,
            'utils_code': utils_code,
            'requirements': requirements,
            'readme': readme,
            'test_code': test_code
        }
    
    def _generate_main_code(self, project_name, description, model_type, 
                           include_comments, include_visualization):
        """Generate main ML pipeline code"""
        
        class_name = self._to_class_name(project_name)
        
        if model_type == 'classification':
            code = self._generate_classification_code(
                class_name, description, include_comments, include_visualization
            )
        elif model_type == 'regression':
            code = self._generate_regression_code(
                class_name, description, include_comments, include_visualization
            )
        elif model_type == 'clustering':
            code = self._generate_clustering_code(
                class_name, description, include_comments, include_visualization
            )
        else:
            code = self._generate_classification_code(
                class_name, description, include_comments, include_visualization
            )
        
        return code
    
    def _generate_classification_code(self, class_name, description, 
                                     include_comments, include_visualization):
        """Generate classification model code"""
        
        comment = lambda text: f"# {text}\n" if include_comments else ""
        docstring = lambda text: f'"""{text}"""\n' if include_comments else ""
        
        code = f'''"""
{class_name} - Classification Model
{description}

Generated by AI CodeGen Pro
Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, 
    accuracy_score, precision_recall_fscore_support, roc_auc_score
)
import joblib
import warnings
warnings.filterwarnings('ignore')

{comment("Import visualization libraries")}
{"import matplotlib.pyplot as plt" if include_visualization else ""}
{"import seaborn as sns" if include_visualization else ""}
{"""
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
""" if include_visualization else ""}


class {class_name}:
    {docstring(f"Machine Learning Classification Pipeline for {class_name}")}
    
    def __init__(self, random_state=42):
        {docstring("Initialize the ML model with default parameters")}
        self.random_state = random_state
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.is_trained = False
        self.feature_names = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        
        {comment("Initialize model with optimal hyperparameters")}
        self._initialize_model()
    
    def _initialize_model(self):
        {docstring("Initialize RandomForest classifier with tuned parameters")}
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=self.random_state,
            n_jobs=-1
        )
    
    def load_data(self, file_path, target_column='target'):
        {docstring("Load and validate dataset from CSV file")}
        print(f"Loading data from {{file_path}}...")
        
        try:
            self.data = pd.read_csv(file_path)
            print(f"âœ“ Data loaded successfully!")
            print(f"  Shape: {{self.data.shape}}")
            print(f"  Columns: {{list(self.data.columns)}}")
            
            {comment("Check for target column")}
            if target_column not in self.data.columns:
                raise ValueError(f"Target column '{{target_column}}' not found in dataset")
            
            {comment("Display basic statistics")}
            self._display_data_info()
            
            return self.data
            
        except Exception as e:
            print(f"âœ— Error loading data: {{str(e)}}")
            raise
    
    def _display_data_info(self):
        {docstring("Display dataset information and statistics")}
        print("\\n" + "="*50)
        print("Dataset Information")
        print("="*50)
        print(self.data.info())
        print("\\nMissing Values:")
        print(self.data.isnull().sum())
        print("\\nStatistical Summary:")
        print(self.data.describe())
        print("="*50 + "\\n")
    
    def preprocess_data(self, target_column='target', test_size=0.2):
        {docstring("Preprocess data: handle missing values, encode labels, split and scale")}
        print("Preprocessing data...")
        
        {comment("Separate features and target")}
        X = self.data.drop(columns=[target_column])
        y = self.data[target_column]
        
        {comment("Store feature names for later use")}
        self.feature_names = X.columns.tolist()
        
        {comment("Handle missing values")}
        X = self._handle_missing_values(X)
        
        {comment("Encode categorical variables")}
        X = self._encode_categorical_features(X)
        
        {comment("Encode target labels if necessary")}
        if y.dtype == 'object':
            y = self.label_encoder.fit_transform(y)
        
        {comment("Split data into train and test sets")}
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state, stratify=y
        )
        
        {comment("Scale features")}
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)
        
        print(f"âœ“ Preprocessing completed!")
        print(f"  Training set: {{self.X_train_scaled.shape}}")
        print(f"  Test set: {{self.X_test_scaled.shape}}")
        print(f"  Number of classes: {{len(np.unique(self.y_train))}}")
    
    def _handle_missing_values(self, X):
        {docstring("Handle missing values using mean imputation for numeric columns")}
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if X[col].isnull().any():
                X[col].fillna(X[col].mean(), inplace=True)
        
        {comment("Drop rows with missing categorical values")}
        X = X.dropna()
        return X
    
    def _encode_categorical_features(self, X):
        {docstring("Encode categorical features using one-hot encoding")}
        categorical_cols = X.select_dtypes(include=['object']).columns
        if len(categorical_cols) > 0:
            X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
        return X
    
    def train(self, cv_folds=5, tune_hyperparameters=False):
        {docstring("Train the model with optional hyperparameter tuning")}
        print("\\nTraining model...")
        
        if tune_hyperparameters:
            print("Performing hyperparameter tuning...")
            self._hyperparameter_tuning()
        
        {comment("Perform cross-validation")}
        cv_scores = cross_val_score(
            self.model, self.X_train_scaled, self.y_train, 
            cv=cv_folds, scoring='accuracy'
        )
        
        print(f"\\nCross-Validation Results:")
        print(f"  Scores: {{[f'{{score:.4f}}' for score in cv_scores]}}")
        print(f"  Mean CV Accuracy: {{cv_scores.mean():.4f}} (+/- {{cv_scores.std() * 2:.4f}})")
        
        {comment("Train on full training set")}
        self.model.fit(self.X_train_scaled, self.y_train)
        self.is_trained = True
        
        print("âœ“ Training completed!")
        
        return cv_scores
    
    def _hyperparameter_tuning(self):
        {docstring("Perform grid search for hyperparameter optimization")}
        param_grid = {{
            'n_estimators': [50, 100, 200],
            'max_depth': [5, 10, 15],
            'min_samples_split': [2, 5, 10]
        }}
        
        grid_search = GridSearchCV(
            self.model, param_grid, cv=3, 
            scoring='accuracy', n_jobs=-1, verbose=1
        )
        
        grid_search.fit(self.X_train_scaled, self.y_train)
        
        self.model = grid_search.best_estimator_
        print(f"Best parameters: {{grid_search.best_params_}}")
        print(f"Best CV score: {{grid_search.best_score_:.4f}}")
    
    def evaluate(self):
        {docstring("Evaluate model performance on test set")}
        if not self.is_trained:
            raise Exception("Model must be trained before evaluation")
        
        print("\\n" + "="*50)
        print("Model Evaluation")
        print("="*50)
        
        {comment("Make predictions")}
        y_pred = self.model.predict(self.X_test_scaled)
        y_pred_proba = self.model.predict_proba(self.X_test_scaled)
        
        {comment("Calculate metrics")}
        accuracy = accuracy_score(self.y_test, y_pred)
        precision, recall, f1, _ = precision_recall_fscore_support(
            self.y_test, y_pred, average='weighted'
        )
        
        print(f"\\nPerformance Metrics:")
        print(f"  Accuracy:  {{accuracy:.4f}}")
        print(f"  Precision: {{precision:.4f}}")
        print(f"  Recall:    {{recall:.4f}}")
        print(f"  F1-Score:  {{f1:.4f}}")
        
        {comment("Display classification report")}
        print("\\nDetailed Classification Report:")
        print(classification_report(self.y_test, y_pred))
        
        {comment("Confusion Matrix")}
        cm = confusion_matrix(self.y_test, y_pred)
        print("\\nConfusion Matrix:")
        print(cm)
        
        {"self._plot_confusion_matrix(cm)" if include_visualization else ""}
        {"self._plot_feature_importance()" if include_visualization else ""}
        {"self._plot_roc_curve(y_pred_proba)" if include_visualization else ""}
        
        print("="*50)
        
        return {{
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'confusion_matrix': cm
        }}
    
    {self._get_visualization_methods() if include_visualization else ""}
    
    def predict(self, X):
        {docstring("Make predictions on new data")}
        if not self.is_trained:
            raise Exception("Model must be trained before prediction")
        
        {comment("Preprocess input data")}
        X_processed = self._preprocess_new_data(X)
        X_scaled = self.scaler.transform(X_processed)
        
        {comment("Make predictions")}
        predictions = self.model.predict(X_scaled)
        probabilities = self.model.predict_proba(X_scaled)
        
        return predictions, probabilities
    
    def _preprocess_new_data(self, X):
        {docstring("Preprocess new data for prediction")}
        {comment("Apply same preprocessing as training data")}
        if isinstance(X, pd.DataFrame):
            X = self._handle_missing_values(X)
            X = self._encode_categorical_features(X)
        return X
    
    def save_model(self, filepath='model.pkl'):
        {docstring("Save trained model and preprocessors to disk")}
        if not self.is_trained:
            raise Exception("Model must be trained before saving")
        
        model_data = {{
            'model': self.model,
            'scaler': self.scaler,
            'label_encoder': self.label_encoder,
            'feature_names': self.feature_names
        }}
        
        joblib.dump(model_data, filepath)
        print(f"âœ“ Model saved to {{filepath}}")
    
    def load_model(self, filepath='model.pkl'):
        {docstring("Load trained model from disk")}
        model_data = joblib.load(filepath)
        
        self.model = model_data['model']
        self.scaler = model_data['scaler']
        self.label_encoder = model_data['label_encoder']
        self.feature_names = model_data['feature_names']
        self.is_trained = True
        
        print(f"âœ“ Model loaded from {{filepath}}")


def main():
    {docstring("Main execution function")}
    print("="*70)
    print(f"  {{'{class_name}'.upper()}}")
    print(f"  {description}")
    print("="*70)
    
    {comment("Initialize model")}
    model = {class_name}()
    
    {comment("Load data")}
    model.load_data('data.csv', target_column='target')
    
    {comment("Preprocess data")}
    model.preprocess_data(target_column='target', test_size=0.2)
    
    {comment("Train model")}
    model.train(cv_folds=5, tune_hyperparameters=False)
    
    {comment("Evaluate model")}
    metrics = model.evaluate()
    
    {comment("Save trained model")}
    model.save_model('trained_model.pkl')
    
    print("\\nâœ“ Pipeline completed successfully!")
    print("="*70)


if __name__ == "__main__":
    main()
'''
        
        return code
    
    def _get_visualization_methods(self):
        """Generate visualization methods"""
        return '''
    def _plot_confusion_matrix(self, cm):
        """Plot confusion matrix heatmap"""
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)
        plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
        plt.ylabel('True Label', fontsize=12)
        plt.xlabel('Predicted Label', fontsize=12)
        plt.tight_layout()
        plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ“ Confusion matrix saved to confusion_matrix.png")
    
    def _plot_feature_importance(self):
        """Plot top feature importances"""
        if hasattr(self.model, 'feature_importances_'):
            importances = pd.DataFrame({
                'feature': self.feature_names,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False).head(15)
            
            plt.figure(figsize=(12, 6))
            sns.barplot(data=importances, x='importance', y='feature', palette='viridis')
            plt.title('Top 15 Feature Importances', fontsize=16, fontweight='bold')
            plt.xlabel('Importance Score', fontsize=12)
            plt.ylabel('Features', fontsize=12)
            plt.tight_layout()
            plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
            plt.close()
            print("âœ“ Feature importance plot saved to feature_importance.png")
    
    def _plot_roc_curve(self, y_pred_proba):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        if len(np.unique(self.y_test)) == 2:
            fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba[:, 1])
            roc_auc = auc(fpr, tpr)
            
            plt.figure(figsize=(8, 6))
            plt.plot(fpr, tpr, color='darkorange', lw=2, 
                    label=f'ROC curve (AUC = {roc_auc:.2f})')
            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('False Positive Rate', fontsize=12)
            plt.ylabel('True Positive Rate', fontsize=12)
            plt.title('Receiver Operating Characteristic (ROC) Curve', 
                     fontsize=14, fontweight='bold')
            plt.legend(loc="lower right")
            plt.grid(alpha=0.3)
            plt.tight_layout()
            plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')
            plt.close()
            print("âœ“ ROC curve saved to roc_curve.png")
'''
    
    def _generate_regression_code(self, class_name, description, 
                                  include_comments, include_visualization):
        """Generate regression model code"""
        # Similar structure to classification but with regression metrics
        return "# Regression code template"
    
    def _generate_clustering_code(self, class_name, description,
                                  include_comments, include_visualization):
        """Generate clustering model code"""
        # Similar structure with clustering algorithms
        return "# Clustering code template"
    
    def _generate_utils_code(self, model_type, include_comments):
        """Generate utility functions"""
        return '''"""
Utility Functions
Helper functions for data processing and visualization
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, r2_score

def load_and_clean_data(filepath, missing_strategy='mean'):
    """
    Load and clean dataset with various missing value strategies
    
    Args:
        filepath: Path to CSV file
        missing_strategy: Strategy for handling missing values
                         ('mean', 'median', 'drop', 'forward_fill')
    
    Returns:
        Cleaned pandas DataFrame
    """
    df = pd.read_csv(filepath)
    
    if missing_strategy == 'mean':
        df = df.fillna(df.mean())
    elif missing_strategy == 'median':
        df = df.fillna(df.median())
    elif missing_strategy == 'drop':
        df = df.dropna()
    elif missing_strategy == 'forward_fill':
        df = df.fillna(method='ffill')
    
    return df


def detect_outliers(data, columns, method='iqr', threshold=1.5):
    """
    Detect outliers in specified columns
    
    Args:
        data: pandas DataFrame
        columns: List of column names to check
        method: 'iqr' or 'zscore'
        threshold: Threshold for outlier detection
    
    Returns:
        DataFrame with outlier flags
    """
    outliers = pd.DataFrame()
    
    for col in columns:
        if method == 'iqr':
            Q1 = data[col].quantile(0.25)
            Q3 = data[col].quantile(0.75)
            IQR = Q3 - Q1
            outliers[col] = ((data[col] < (Q1 - threshold * IQR)) | 
                            (data[col] > (Q3 + threshold * IQR)))
        elif method == 'zscore':
            z_scores = np.abs((data[col] - data[col].mean()) / data[col].std())
            outliers[col] = z_scores > threshold
    
    return outliers


def plot_data_distribution(data, columns, save_path='distribution.png'):
    """Plot distribution of features"""
    n_cols = len(columns)
    n_rows = (n_cols + 2) // 3
    
    fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5*n_rows))
    axes = axes.flatten()
    
    for idx, col in enumerate(columns):
        sns.histplot(data[col], kde=True, ax=axes[idx])
        axes[idx].set_title(f'Distribution of {col}')
        axes[idx].set_xlabel(col)
        axes[idx].set_ylabel('Frequency')
    
    # Hide empty subplots
    for idx in range(n_cols, len(axes)):
        axes[idx].set_visible(False)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()


def calculate_regression_metrics(y_true, y_pred):
    """Calculate regression performance metrics"""
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    mae = np.mean(np.abs(y_true - y_pred))
    
    return {
        'MSE': mse,
        'RMSE': rmse,
        'R2': r2,
        'MAE': mae
    }


def export_results_to_csv(predictions, probabilities, filepath='predictions.csv'):
    """Export predictions to CSV file"""
    results_df = pd.DataFrame({
        'Prediction': predictions,
        'Probability': probabilities.max(axis=1) if len(probabilities.shape) > 1 else probabilities
    })
    
    results_df.to_csv(filepath, index=False)
    print(f"Results exported to {filepath}")
'''
    
    def _generate_requirements(self, model_type, include_visualization):
        """Generate requirements.txt"""
        base_requirements = [
            "numpy==1.24.3",
            "pandas==2.0.3",
            "scikit-learn==1.3.0",
            "joblib==1.3.2"
        ]
        
        if include_visualization:
            base_requirements.extend([
                "matplotlib==3.7.2",
                "seaborn==0.12.2"
            ])
        
        if model_type in ['classification', 'regression']:
            base_requirements.append("xgboost==1.7.6")
        
        return "\n".join(base_requirements)
    
    def _generate_readme(self, project_name, description, model_type):
        """Generate README.md"""
        return f"""# {project_name}

{description}

## Overview
This machine learning project was automatically generated by AI CodeGen Pro.
It implements a complete {model_type} pipeline with data preprocessing, model training, 
evaluation, and prediction capabilities.

## Features
- âœ¨ Automated data loading and preprocessing
- ðŸ”§ Missing value handling
- ðŸ“Š Feature scaling and encoding
- ðŸ¤– Model training with cross-validation
- ðŸ“ˆ Comprehensive performance evaluation
- ðŸ’¾ Model persistence (save/load)
- ðŸ“‰ Visualization of results
- ðŸŽ¯ Hyperparameter tuning

## Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Install Dependencies
```bash
pip install -r requirements.txt
```

## Usage

### Basic Usage
```python
from main import {self._to_class_name(project_name)}

# Initialize model
model = {self._to_class_name(project_name)}()

# Load and preprocess data
model.load_data('data.csv', target_column='target')
model.preprocess_data()

# Train model
model.train(cv_folds=5)

# Evaluate performance
metrics = model.evaluate()

# Save model
model.save_model('trained_model.pkl')
```

### Making Predictions
```python
# Load trained model
model.load_model('trained_model.pkl')

# Make predictions
predictions, probabilities = model.predict(new_data)
```

## Project Structure
```
.
â”œâ”€â”€ main.py              # Main model implementation
â”œâ”€â”€ utils.py             # Utility functions
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md           # This file
```

## Model Performance
The model's performance will be displayed after training, including:
- Accuracy, Precision, Recall, F1-Score
- Confusion Matrix
- Feature Importance
- ROC Curve (for binary classification)

## Generated Files
After running the pipeline, the following files will be created:
- `trained_model.pkl`: Saved model
- `confusion_matrix.png`: Confusion matrix visualization
- `feature_importance.png`: Feature importance plot
- `roc_curve.png`: ROC curve (if applicable)

## Customization
You can customize the model by modifying parameters in the `__init__` method:
- `n_estimators`: Number of trees in Random Forest
- `max_depth`: Maximum depth of trees
- `test_size`: Proportion of test set
- `cv_folds`: Number of cross-validation folds

## Requirements
See `requirements.txt` for full list of dependencies.

## Generated by
**AI CodeGen Pro** - {datetime.now().strftime("%Y-%m-%d")}

## License
This project is generated automatically and can be used freely.

## Support
For issues or questions about the generated code, please refer to AI CodeGen Pro documentation.
"""
    
    def _generate_tests(self, project_name, model_type):
        """Generate unit tests"""
        class_name = self._to_class_name(project_name)
        
        return f'''"""
Unit Tests for {project_name}
"""

import unittest
import numpy as np
import pandas as pd
from main import {class_name}


class Test{class_name}(unittest.TestCase):
    """Test cases for {class_name}"""
    
    def setUp(self):
        """Set up test fixtures"""
        self.model = {class_name}()
        
        # Create dummy data
        np.random.seed(42)
        self.dummy_data = pd.DataFrame({{
            'feature1': np.random.rand(100),
            'feature2': np.random.rand(100),
            'target': np.random.randint(0, 2, 100)
        }})
        self.dummy_data.to_csv('test_data.csv', index=False)
    
    def test_initialization(self):
        """Test model initialization"""
        self.assertIsNotNone(self.model)
        self.assertFalse(self.model.is_trained)
    
    def test_load_data(self):
        """Test data loading"""
        data = self.model.load_data('test_data.csv')
        self.assertEqual(len(data), 100)
    
    def test_preprocess_data(self):
        """Test data preprocessing"""
        self.model.load_data('test_data.csv')
        self.model.preprocess_data()
        self.assertIsNotNone(self.model.X_train_scaled)
        self.assertIsNotNone(self.model.y_train)
    
    def test_training(self):
        """Test model training"""
        self.model.load_data('test_data.csv')
        self.model.preprocess_data()
        self.model.train(cv_folds=3)
        self.assertTrue(self.model.is_trained)
    
    def tearDown(self):
        """Clean up test files"""
        import os
        if os.path.exists('test_data.csv'):
            os.remove('test_data.csv')


if __name__ == '__main__':
    unittest.main()
'''
    
    @staticmethod
    def _to_class_name(project_name):
        """Convert project name to valid class name"""
        # Remove special characters and convert to PascalCase
        name = re.sub(r'[^a-zA-Z0-9\s]', '', project_name)
        name = ''.join(word.capitalize() for word in name.split())
        return name if name else 'MLModel'  